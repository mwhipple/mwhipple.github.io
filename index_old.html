  </p>

  <h4>Details</h4>

  <p>
    My starting point is to use the provided image and access a locally running site...unforutnately some of my quick tweaks didn't
    quite land so I'll need to quickly retrieve specifics from the <a href="#src-docker-reference">Docker reference documentation</a>
    since I typically can remember what options there are but not quite how they look. While I (as mentioned) am looking to move away
    from Docker it has good documentation and remains the de facto standard at the moment so starting with what is documented for Docker
    is certainly a safe point while pursuing what is currently Docker-compatible invocations.
  </p>

  <p>
    To get the ball rolling I just fiddled with the command to get it to work, but I'll adjust them based on the
    <a href="#src-docker-run">docker run documentation</a> and replace the short options with the longer forms.
  </p>

</div>

<div class="section">

  <h2>Programming Languages are Harmful</h2>

  <h3>Backstory</h3>

  <p>
    Over my career I've programmed in a range of different languages and I'm currently nursing an idea that languages offer tenuous
    return on investment to the software industry. Don't get me wrong, I certainly think many languages have contributed many great
    ideas and I'm also vehemently opposed to panaceas and golden hammers and therefore recognize that some problems are best explored
    using appropriate means of expression.
  </p><p>
    The back-breaking straw of this idea was likely spending a chunk of one of my days spelunking through Python's SSL implementation and 
    corresponding C code to work through a bug
    whose behavior I could readily reproduce and resolve using the <code>openssl</code> command. While I used this as a chance to
    brush up on some TLS details the main lingering impression was the large tracts of code that existed not to do anything new, but
    simply to reexpress an established solution (the particular issue was resolved by swapping out LibreSSL for OpenSSL).
  </p><p>
    Some other recent background context was likely being engaged in several conversations around language adoption, and somewhat
    relatively recently within an engineering culture that had a <q>one language to rule them all</q> mindset even when the output
    of that mindset was often bizarre paths of using that language to invoke shell commands to launch other languages or containers
    (which I looked to simplify as things broke...which they often did).
  </p>

  <h3>Software Tools and Monoliths</h3>

  <p>
    A well-known exchange in the annals of computing history is Doug McIlroy's criticism of a program Don Knuth wrote to demonstrate
    literate programming for Jon Bentey's <q>Programming Pearls</q> CACM column (with the underlying premise that if software is treated
    as literature it should be subjected to criticism). While there is a fair amount to glean from all of the material, one of the main
    takeaways is that McIlroy was able to counter Knuth's multi-page application with a short and fairly basic Unix pipeline.
    The prospect of software tools composed with uniform pipes offered an approach which could be more quickly produced, more readily
    evolved, and was more able to tap portable background knowledge.
  </p><p>
    As alluded to the discussion is a bit more nuanced and as one of my former coworkers posited that argument is on much shakier ground
    when considering a system such as TeX (and I personally am a proponent of literate programming), but it is worth recognizing that all
    too often programming languages seem to drift towards such monolithic recreations of functionality which could otherwise be more readily
    composed. From a more modern perspective many of the software tools ideas carry forward to pursuits such as microserves...or less
    ambitiously any use of well designed utility containers.
  </p>

  <h3>The What and the How</h3>

  <p>
    At its core, programming is largely about algorithms and algorithms are the imperative complement to declarative knowledge.
    A clear and often used example (I think it appears in sources such as The Art of Computer Programming and The Go Programming Language)
    is <em>how</em> Euclid's Algorithm can be coded to determine <em>what</em> is the greatest common divisor (GCD) of two numbers.
    The GCD is an important declared concept and the automation of how to derive the appropriate value is enormously valuable.
  </p><p>
    While automating such processes is the core value of computers, one of the most valuable tools in engineering is that of
    abstraction. Abstraction is essential for making systems comprehensible and while it is crucial in all fields of engineering,
    it is integral to software engineering - not only is the base level of software engineering built atop many layers of electrical
    engineering abstractions, but the creation of abstractions is one of the core tools of software engineers.
    Abstraction effectively buries the previously mentioned core value of computing; drawing on the earlier example while the value of
    <em>computers</em> is the automation of the <em>how</em> of Euclid's Algorithm, the value delivered by the software is that
    of producing the <em>what</em> of the GCD. Therefore the produced machine is most simply represented as a <em>what</em> producing
    blackbox so the GCD and any other relevant pieces of data can be used without getting swamped in details.
  </p><p>
    Unfortunately languages are often too focused on aspects of <em>how</em> - all too often there are established and abstracted solutions
    for particular problems but all too often significant additional effort is required to reimplement or adapt such solutions so that
    they conform with <em>how</em> a particular language seeks to express ideas within the solution space. This perspective in isolation is
    a bit simplistic but will be elaborated upon further.
  </p>

  <h3>Systems vs. Application Programming</h3>

  <p>
    A key distinction when discussing programming is that between systems programming and application programming. The official definitions
    should be incorporated here, but for in the short term I'll consider systems programming as that which is focused on enabling use of what
    is immediately available. At the lowest level this involves things like hardware and instruction sets but more typically this is
    likely to make use of the facilities provided by the operating system or higher level of abstraction such as virtual machines. The output
    of systems programming is likely to be a generalized machine.
  </p><p>
    Applications programming is developing software to solve specific business cases...which is the vast majority of modern software being
    created. Drawing on Fred Brooks's <q>No Silver Bullet</q>, the vast majority of concerns introduced by software in applications programming
    amount to accidental complexity: friction which is introduced by the solution space where only a small amount is likely to be an essential
    consideration for the problem at hand. Unfortunately software engineers seem to gravitate towards challenges that may be technically
    interesting but have unclear business value. A basic smell test for such considerations is whether their removal would confer a competitive
    advantage - if you're investing in establishing deep technical expertise but a competitor made use of an alternative which avoided that
    overhead would they be able to undercut you? If that resonates then it is a strong indication of an accretion of accidental complexity
    which is likely to escalate both delivery and maintenance costs. No-code, low-code, and ML-assisted development may help reduce smooth out
    some of these edges but a far more fundamental adjustment is simply to recognize the difference between systems and application programming
    and the natural corollary that unless your core deliverable is software itself rather than the output of such software, any and all effort
    expended in producing such output with the desired characteristics is cost and should be managed appropriately. There's a larger thread
    lurking within this sentiment around accountability and how perverse some routine engineering efforts would seem if analogs within other
    departments existed but are accepted in the magical world of software, but that's likely a larger topic.
  </p><p>
    Much of this ties directly back to the concepts in <q>The What and the How</q>: application programming is best expressed entirely in
    terms of <em>what</em>s. Preferring more declarative interfaces can make machines far more economical to develop and easier to reason about,
    verify, and optimize. Most application programming, however, tends to remain largely imperative without a clear delineation from systems
    programming. This break is certainly not a clearly achievable goal and is likely to echo the largely unrealized dream of fourth generation
    languages, <em>but</em> a key distinction in this thread is that the focus is emphatically not about pursuing a language but rather reuse
    and composition of abstractions. This also touches back upon <q>Software Tools and Monoliths</q> and echoes some of Martin Kleppmann's
    sentiments at the end of <a href="#src-ddai">Desiging Data-Intensive Applications</a> which imagines being able to compose data flows
    as easily as Unix pipelines.
  </p>

  <h3>Underlying Concerns</h3>

  <p>
    The previous ideas stay pretty conceptual but all of these ideas need to meet the metal at some point and some of the things that
    have been glossed over need warrant some attention.
  </p><p>
    Perhaps one of the first places to start is that much of the described interoperability is available in the form of 
    foreign function interfaces...but foreign? If two languages are running on the same system what is foreign? This cuts back to
    the Python SSL code that pushed me over this ledge - why was so much code necessary to call a library that I could easily interact
    with from the command line?
  </p><p>
    One of the clearest initial issues is the representation of data within any given language. Most instruction sets operate on
    bits and while they may care about the number of bits involved they are far less likely to care about what the bits mean; semantics
    that extend beyond basics such as a sign bit are likely to be largely handled by convention. While low level languages like C provide
    some behavior on top of this such behavior is largely in the compiler so the data worked with is still largely bits rather than
    having any particularly defined metadata. As most major operating systems are written in a C compatible language this leaves
    higher level languages to track what additional data they need either alongside the data itself or in separate structures, establishing
    local conventions which then need a translation layer for "foreign" data.
  </p><p>
    A related but arguably less fundamental concern is around some of the additional behavior provided by particular languages.
    Concerns such as memory management or safety may require that any data which is not provided through standard channels must be
    somehow taken into the fold. This is significant but ultimately this should correspond to some combination of the aforementioned
    metadata and perhaps a function invocation. There are certainly stickier considerations if data is registered for such functionality
    while remaining accessible to external code, but those are detail devils that are ultimately the result of some of the initial
    practices which are being questioned (if such functionality were orthogonal to some notion of "language" then the foreign/external
    boundary disappears.
  </p><p>
    When considering established approaches such as unix pipelines a hidden concern is that of inter-process communication (IPC).
    Consistently sharing data by value is wonderfully simple...but can be fairly costly. The same concern manifests in microservices
    and the goals of GNU Hurd. On a given system this is another incarantion of the previous concern: any perceived <em>requirement</em>
    that the value must be handled in a particular way is the result of it crossing some potentially arbitrary boundary.
  </p>

  <h2>Where This Leads</h2>

  <p>
    I'll be exploring some of the options with some of the ideas above, much of this circles around the notion of relying upon an
    established low level interface to avoid some of the translation boundaries, where the clearest initial such interface would
    be the SysV ABI. Particular features of given languages would be implemented independently of the language itself, and the
    means of expression which often seem to dominate current languages would be a layer on top of all of these (like a lightweight
    compiler frontend). This will probably result primarily in adoption of tools which match these goals (I feel like I may be
    getting pulled toward C++) with some gaps filled by some homemade glue (particularly for some of the additional tastes like
    literate programming).
  </p>

</div>

<div class="section">

  <h2>Microservices</h2>

  <p>
    Microservice architectures (MSAs) are a widely pursued buzzword. Although most of the guidance seems to be <q>try anything else first</q>,
    many organizations eagerly dive in in the hopes that MSAs offer some kind of solution in terms of scale, or cost, or organizational friction.
    Any of these ideas are valid...with a few pages worth of criteria.
  <p>

  <h3>Popping Some Bubbles</h3>

  <p>
    In terms of both scale and cost some of the major considerations are in terms of higher initial overhead and the Pareto Principle.
    MSAs out of the gate have higher costs (in all forms) and likely lower performance due to more expensive communication across nodes
    which has adverse impacts on being able to scale cost effectively. The Pareto Principle is likely the more significant consideration
    as the assertion that the ability to scale pieces of your infrastructure independently is undermined by the notion that there are likely
    to be relatively few hot spots. This counterargument is furthered by the notion that latency sensitive apps also have bursty traffic
    patterns and therefore a cluster of those hot spots is likely to have sufficient spare cycles at any given time to handle the ~20% of
    lower volume traffic. This mirrors some of the benefits espoused by colocating containers which are often wrapped in misconceptions around
    how such work will be isolated and resources will be shared - while attention should be paid to concerns such as process scheduling
    such behavior can be configured at the level of the OS (which is where it is handled in containers) or the relevant VM.
  </p>

  <p>
    In terms of organizational structure, MSAs can be a useful <em>tool</em> but are not a solution. A naive adoption of microservices will
    not deliver the desired autonomy and agility but simply obscure the inherited friction and the overall system is likely to amount to
    a "distributed monolith".  Conway's Law can be a useful guiding framework for these types of decisions but too often it seems to be
    given lip service without deeper inspection with the idea that independent teams will somewhow bestow independence on the systems that
    they own, rather than the two needing to be defined together; tactics like the Reverse Conway Maneuver should be driven by data
    and design rather than optimism otherwise any existing drag will simply be amplified as it passes through both systems and people.
    This manifests in both development time (coordinating on what to build) and runtime (tracking the successul delivery of value to users).
    There are clear benefits <em>iff</em> there is independence which microservices can help reinforce but not enable.
  </p>

  <p>
    Another quick and hopefully obvious concern to track is around simplicity. The cognitive overhead of designing and operating microservices
    tends to be notably higher. There can be benefits in constraining the amount of logic and concepts present in a given context, but
    the benefits of such chunking does not naturally translate to distributing the systems themselves.
  </p>

  <h3>A Saner Perpsective</h3>

  <p>
    One of the main contributing factors to the prospect of Microservices is the simple feasibility of the approach. Launching an arbitrary
    number of instances of free open source software does not raise licensing costs, and many of the concerns around orchestrating and
    running such an architecture have been worked out at this point. Unfortunately the initial adoption of Microservices seems to have jumped
    over one of the most valuable potentials in this world in that it can deliver the <em>decoupling of software from how and where it is deployed.</em>
    Through this lens, the application of microservices as an organizational driver rather than more of a technical detail poses higher coupling
    and commensurate lower agility.
  </p>

  <p>
    Rather than orienting around the notion of "microservices" the focus should be on the already well established, more abstract, divison
    of "modules". Perhaps the crucial distinction is by preserving the freedom to modify what a software does and how it is deployed, the
    technical headaches of microservices can be addressed with more dedication. While domain knowledge is typically the heaviest lift in
    designing software and leveraging approaches such as defined Bounded Contexts can provide massive benefits, attempting to apply
    such practices across all levels contradicts some of the more fundamental precepts concerning isolating business logic from
    infrastructural concerns.
  </p>

  <p>
    By recognizing that many of the modern tools and practices can be leveraged not as a means to realize particular deployment strategies
    but rather to more freely mix and move across such options, the tradeoffs can be assessed orthogonally along the axes of domain and
    technical boundaries. On the most basic level the assertion that logical seperation should carry through to physical separation (i.e. hardware)
    seems tenuous and, within the context of modern tooling, flawed and in fairly direct conflict with the typical model involving generalized
    compute which likely goes all the way down to the random-access machine model underlying most application development.
  </p>

  <p>
    Restablishing such separation allows the deployment model and the stickier concerns that arise with distributed systems to be assessed 
    from a technical perspective. Within a larger system and often within given bounded domain contexts there are likely to be boundaries
    that can be established. Concerns such as data locality, transactionality, failure domains, resource usage,
    and non-functional requirements/architectural characteristics are all likely to be very useful in assessing the deployment model and as
    may be evident there could easily be a
    many-to-many mapping between such concerns and the domain contexts which the machine is serving, and accordingly the owners of the logic.
  </p>

  <p>
    A major prerequisite of the purported agility afforded by this separation is precise requirements (which is arguably always a prerequisite
    for safe agility along with corresponding verification). Both functional and non-functional requirements should be refined to clearly
    express what is <em>necessary</em>, otherwise systems are likely to end up locked in what may have been an incidental deployment decision
    due to the concerns outlined above. This is often one of the major contributors to the aforementioned trap of a distributed monolith in that
    if the requirements don't clearly articulate the particulars of given use cases then the system may end up contorted to match assumptions
    or an inappropriate topology.
  </p>

  <h3>Operability</h3>

  <p>
    An aspect which seems diverting to is operation of a running system. This was briefly mentioned earlier and is also implicit in many of
    the other sentiments. The underlying premise here is being able to change deployment models and therefore operational concerns become
    another parameter in making such decisions. There is a simplistic perception that microservices and a relationship to team boundaries
    can aid in operations but there are several factors that may inhibit that. As with other considerations the overall overhead increases
    as things are distributed and there should therefore be a path to the breakeven point which also takes into consideration people and
    skillsets. In addition to more general goals such as observability this can also manifest in the form of expertise around how particular
    focused technologies are being used or potentially how more generalized technologies are being stretched. Additionally, as mentioned earlier,
    clear visiblity into a single system does not provide inherent value if it is a piece of a larger puzzle and therefore from a business
    perspective may lead to passing the buck or pointing fingers. 
  </p>

  <p>
    This concern seems worth individual attention since I've noticed it raised specifically in conversations, but it fits the same pattern as
    other points herein in that the resulting state tends to reflect and often amplify the underlying forces rather than benefiting from any magic sauce.
    If you have clear visibility into your overall system and are able to smoothly work with it then you're doing the right thing,
    if you don't then it should be handled as a first-class concern rather than expecting it to by a byproduct of a buzzword.
  </p>

  <h3>In Practice</h3>

  <p>
    All of the above speaks to the desire to decouple software and the associated development efforts from how it is deployed, and a natural
    way to gauge the effectiveness of such a pursuit is deployment flexibility. There are at least four distinct deployment models that come
    to mind:
    <ul>
      <li>a library in a monolith or other deployment</li>
      <li>a container within a scheduled pod</li>
      <li>a standalone service</li>
      <li>function as a service</li>
    </ul>
    If code can be faily easily moved between some of these options then the desired agiliity has been realized. The decision to adopt
    one over the other can therefore be more easily evolved in light of some of the underlying tradeoffs, requirements, and data.
  </p>

  <p>
    The principles underlying much of this are not new by any stretch; if there's a separation of concerns which makes use of modulariy
    and inversion of control then the core logic should be decoupled from infrastructural concerns and ultimately the difference between
    any of the above amount to such infrastructural decisions. Such principles unfortunately often seem neglected, but proper adherence
    (and potential enforcement) should provide a good baseline for such independence.
  </p>

  <p>
    From what I gather this idea seems to be at the heart of the Clojure <em>Polylith</em> project which one of my colleages references
    periodically but I honestly still haven't had the time to investigate with any depth. As implied I tend to view much of this as a
    natural consequence of good design rather than requiring any additional machinery (which may be the case for many things).
  </p>

  <p>
    In terms of a wider organization this will manifest more concretely in a "library-first" design principle. The produced library
    artifact could then be pulled in for use in any of the environments listed above, and as it evolves many of the deployment
    containers could also be largely standardized such that they do not require additional coding. The library itself should follow
    what should also be standard expectations around libraries - minimal dependencies that fit within an IS-A relationship and
    therefore intended for use with inversion of both control and dependencies.
  </p>

</div>

<div class="section">

  <h2>References</h2>

  <ol class="sources">

    <li><a id="src-gnucoreutils_manual" data-in="src-ddia" href="https://www.gnu.org/software/coreutils/manual/html_node/index.html">GNU Coreutils Manual</a></li>
    <li><a id="src-github_blog" data-in="src-ddia" href="https://github.blog">GitHub Blog</a></li>
    <li><a id="src-gnuartanis" data-in="src-gnumanuals" href="https://www.gnu.org/software/artanis">GNU Artanis</a></li>
    <li><a id="src-gnuguile" data-in="src-gnumanuals" href="https://www.gnu.org/software/guile">GNU Guile</a></li>

    <li><a id="src-artanis_gitlab" data-in="src-gnuartanis" href="https://gitlab.com/hardenedlinux/artanis">HardenedLinux / artanis</a></li>
    <li><a id="src-github_blog_rebase_9" data-in="src-github_blog" href="https://github.blog/2008-12-22-github-rebase-9">GitHub Rebase #9 | The GitHub Blog</a></li>
    <li><a id="src-gae-cloud-run" data-in="src-gae-flexible" href="https://cloud.google.com/appengine/docs/flexible/cloud-run-for-gae-customers">
      Cloud Run for App Engine customers | Google App Engine flexible environment docs | Google Cloud
    </a></li>
    <li><a id="src-gae-custom-quickstart" data-in="src-gae-flexible" href="https://cloud.google.com/appengine/docs/flexible/custom-runtimes/create-app">
      Quickstart: Create a custom runtime app in the App Engine flexible environment  |  Google App Engine flexible environment docs  |  Google Cloud
    </a></li>
    <li><a id="src-gcloud" href="https://cloud.google.com/sdk/docs" data-in="src-gae-custom-quickstart">
      Google Cloud CLI documentation | Google Cloud CLI Documentation
    </a></li>
    <li><a id="src-gcloud-quickstart" href="https://cloud.google.com/sdk/docs/install-sdk" data-in="src-gcloud">
      Quickstart: Install the Google Cloud CLI  |  Google Cloud CLI Documentation
    </a></li>

    <li><a id="src-nalaginrut" data-in="src-artanis_gitlab" href="https://nalaginrut.com">Samson's Machete</a></li>
    <li><a id="src-nalaginrut-artanis_docker" data-in="src-artanis_gitlab" href="https://nalaginrut.com/archives/2019/09/18/install%20gnu%20artanis%20with%20docker">
      Samson's Machete (Install GNU Artanis with Docker)
    </a></li>
    <li><a id="src-docker-get" data-in="src-nalaginrut-artanis_docker" href="https://docs.docker.com/get-docker/">Get Docker | Docker Documentation</a></li>
    <li><a id="src-docker-reference" data-in="src-docker-get" href="https://docs.docker.com/reference">Reference documentation | Docker Documentation</a></li>
    <li><a id="src-docker-cli" data-in="src-docker-reference" href="https://docs.docker.com/engine/reference/commandline/cli">Use the Docker command line | Docker Documentation</a></li>
    <li><a id="src-docker-run" data-in="src-docker-run" href="https://docs.docker.com/engine/reference/commandline/run">docker run | Docker Documentation</a></li>
    <li><a id="src-github_blog_git_site" data-in="src-github_blog" href="https://github.blog/2008-07-26-new-git-site/">
      New Git Site | The GitHub Blog
    </a></li>
    <li><a id="src-nalaginrut-artanis_0.5_docker" href="https://nalaginrut.com/archives/2021/02/16/gnu%20artanis-0.5%20is%20ready%20for%20docker">
      Samsons's Machete (GNU Artanis-0.5 is ready for docker)
    </a></li>
    <li><a id="src-nalaginrut-hurd" href="https://nalaginrut.com/archives/2019/12/11/hurd%2c%20sel4%2x%20thoughts">
      Samsons's Machete (Hurd, seL4, thoughts)
    </a></li>
  </ol>
</div>

</body>

</html>
